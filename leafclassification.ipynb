{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5408,"databundleVersionId":38263,"sourceType":"competition"},{"sourceId":214819281,"sourceType":"kernelVersion"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!unzip /kaggle/input/leaf-classification/images.zip -d /kaggle/working/\n!unzip /kaggle/input/leaf-classification/train.csv.zip -d /kaggle/working/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import used libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torch.nn.functional as F\nimport itertools\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T06:29:42.083260Z","iopub.execute_input":"2024-12-26T06:29:42.083587Z","iopub.status.idle":"2024-12-26T06:29:47.140247Z","shell.execute_reply.started":"2024-12-26T06:29:42.083564Z","shell.execute_reply":"2024-12-26T06:29:47.139373Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualizing a subset of the leaf images","metadata":{}},{"cell_type":"code","source":"def visualize_images(df, images_dir, num_images=5):\n    plt.figure(figsize=(15, 8))\n    random_rows = df.sample(num_images)\n    for i, row_idx in enumerate(random_rows.index):\n        \n        img_id = row_idx\n        img_path = os.path.join(images_dir, f'{img_id}.jpg')\n        img = Image.open(img_path)\n        plt.subplot(1, num_images, i + 1)\n        plt.imshow(img, cmap='gray')\n        plt.title(f'ID: {img_id}')\n        plt.axis('off')\n    plt.suptitle('Sample Leaf Images')\n    plt.tight_layout(rect=[0, 0, 1, 0.95]) # Makes title not overlap\n    plt.show()\n\ntrain_df = pd.read_csv('/kaggle/working/train.csv')\nvisualize_images(train_df, '/kaggle/working/images')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T08:22:46.622905Z","iopub.execute_input":"2024-12-26T08:22:46.623239Z","iopub.status.idle":"2024-12-26T08:22:47.078956Z","shell.execute_reply.started":"2024-12-26T08:22:46.623218Z","shell.execute_reply":"2024-12-26T08:22:47.078054Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load and prepare data for training","metadata":{}},{"cell_type":"code","source":"def load_and_preprocess_data(csv_path, images_dir):\n    # Load data\n    data = pd.read_csv(csv_path)\n\n    # Separate shape, texture, and margin features\n    shape_cols = [col for col in data.columns if 'shape' in col]\n    texture_cols = [col for col in data.columns if 'texture' in col]\n    margin_cols = [col for col in data.columns if 'margin' in col]\n\n    features = data[shape_cols + texture_cols + margin_cols]\n    labels = data['species']\n\n    # Check for missing values\n    print(\"\\nMissing values:\")\n    print(features.isnull().sum().sum())\n\n    # Check for duplicates\n    print(\"\\nDuplicate rows:\")\n    print(data.duplicated().sum())\n\n    # Standardize features\n    scaler = StandardScaler()\n    features_scaled = pd.DataFrame(\n        scaler.fit_transform(features),\n        columns=features.columns,\n        index=data['id']\n    )\n\n    # Encode labels\n    label_encoder = LabelEncoder()\n    labels_encoded = label_encoder.fit_transform(labels)\n\n    print(\"Length of classes: \", len(label_encoder.classes_))\n\n    return features_scaled, labels_encoded, label_encoder.classes_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T08:22:53.236320Z","iopub.execute_input":"2024-12-26T08:22:53.236674Z","iopub.status.idle":"2024-12-26T08:22:53.242793Z","shell.execute_reply.started":"2024-12-26T08:22:53.236644Z","shell.execute_reply":"2024-12-26T08:22:53.241897Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PyTorch Custom Dataset for Leaf Classification: Combining Image and Tabular Data","metadata":{}},{"cell_type":"code","source":"class LeafDataset(Dataset):\n    \"\"\"\n    Custom Dataset class for leaf classification that handles both image and tabular data.\n    \n    Attributes:\n        features (pd.DataFrame): Numerical features (shape, texture, margin)\n        images_dir (str): Directory containing leaf images\n        labels (array-like, optional): Class labels for each sample\n        transform (callable, optional): Optional transform to be applied on images\n        image_ids (array): Array of image IDs\n    \"\"\"\n    def __init__(self, features, images_dir, labels=None, transform=None):\n        self.features = features\n        self.images_dir = images_dir\n        self.labels = labels\n        self.transform = transform\n        self.image_ids = features.index.values\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Get a sample from the dataset.\n        \n        Args:\n            idx (int): Index of the sample\n            \n        Returns:\n            tuple: (image, numerical_features, label) if labels are provided,\n                  (image, numerical_features) otherwise\n        \"\"\"\n        img_id = self.image_ids[idx]\n        img_path = os.path.join(self.images_dir, f'{img_id}.jpg')\n        \n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n            \n        numerical_features = torch.FloatTensor(self.features.iloc[idx].values)\n        \n        if self.labels is not None:\n            label = torch.LongTensor([self.labels[idx]])[0]\n            return image, numerical_features, label\n        return image, numerical_features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"class LeafCNN(nn.Module):\n    \"\"\"\n    Hybrid CNN model that processes both image and tabular data for leaf classification.\n    \n    The model consists of:\n    1. CNN branch for processing images\n    2. MLP branch for processing numerical features\n    3. Combined layers for final classification\n    \n    Args:\n        num_numerical_features (int): Number of numerical input features\n        num_classes (int): Number of output classes\n        dropout_rate (float): Dropout rate for regularization\n    \"\"\"\n    def __init__(self, num_numerical_features, num_classes, dropout_rate=0.5):\n        super(LeafCNN, self).__init__()\n        \n        # CNN architecture for image processing\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            \n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            \n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            \n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            \n            nn.AdaptiveAvgPool2d((1, 1))\n        )\n        \n        # MLP for processing numerical features\n        self.numerical_layers = nn.Sequential(\n            nn.Linear(num_numerical_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            \n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate)\n        )\n        \n        # Combined layers for final classification\n        self.combined_layers = nn.Sequential(\n            nn.Linear(256 + 256, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            \n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, image, numerical_features):\n        \"\"\"\n        Forward pass of the model.\n        \n        Args:\n            image (torch.Tensor): Input image tensor\n            numerical_features (torch.Tensor): Numerical feature tensor\n            \n        Returns:\n            torch.Tensor: Model predictions\n        \"\"\"\n        x_img = self.conv_layers(image)\n        x_img = x_img.view(x_img.size(0), -1)\n        \n        x_num = self.numerical_layers(numerical_features)\n        \n        combined = torch.cat((x_img, x_num), dim=1)\n        return self.combined_layers(combined)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T07:18:10.716074Z","iopub.execute_input":"2024-12-26T07:18:10.716381Z","iopub.status.idle":"2024-12-26T07:18:10.724825Z","shell.execute_reply.started":"2024-12-26T07:18:10.716358Z","shell.execute_reply":"2024-12-26T07:18:10.723921Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training function","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, early_stopping_patience=10):\n    train_losses = []\n    val_losses = []\n    train_accuracies = []\n    val_accuracies = []\n\n    best_val_loss = float('inf')\n    best_epoch = 0\n    epochs_without_improvement = 0\n\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0.0\n        correct_train_predictions = 0\n        total_train_samples = 0\n        for images, numerical_features, labels in train_loader:\n            images, numerical_features, labels = images.to(device), numerical_features.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images, numerical_features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total_train_samples += labels.size(0)\n            correct_train_predictions += (predicted == labels).sum().item()\n\n        train_loss /= len(train_loader)\n        train_accuracy = correct_train_predictions / total_train_samples\n        train_losses.append(train_loss)\n        train_accuracies.append(train_accuracy)\n        # Evaluate on Validation set\n        model.eval()\n        val_loss = 0.0\n        correct_val_predictions = 0\n        total_val_samples = 0\n        with torch.no_grad():\n            for images, numerical_features, labels in val_loader:\n                images, numerical_features, labels = images.to(device), numerical_features.to(device), labels.to(device)\n                outputs = model(images, numerical_features)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                total_val_samples += labels.size(0)\n                correct_val_predictions += (predicted == labels).sum().item()\n\n        val_loss /= len(val_loader)\n        val_accuracy = correct_val_predictions / total_val_samples\n        val_losses.append(val_loss)\n        val_accuracies.append(val_accuracy)\n\n        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f} - Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n        #Scheduler step\n\n        scheduler.step(val_loss) # This needs the validation loss to reduce the learning rate\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_epoch = epoch\n            epochs_without_improvement = 0\n            torch.save(model.state_dict(), 'best_model.pth')\n        else:\n           epochs_without_improvement += 1\n\n        if epochs_without_improvement >= early_stopping_patience:\n           print(f\"Early stopping triggered at epoch {epoch+1}\")\n           break\n\n    print(f\"Best validation loss: {best_val_loss:.4f}, found at epoch {best_epoch+1}\")\n    model.load_state_dict(torch.load('best_model.pth'))\n    return train_losses, val_losses, train_accuracies, val_accuracies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T07:29:48.209592Z","iopub.execute_input":"2024-12-26T07:29:48.209946Z","iopub.status.idle":"2024-12-26T07:29:48.219175Z","shell.execute_reply.started":"2024-12-26T07:29:48.209918Z","shell.execute_reply":"2024-12-26T07:29:48.218219Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluating the model on testing data","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, test_loader, criterion, device, classes):\n    \"\"\"\n    Evaluate the model's performance on a test set.\n    \n    Args:\n        model (nn.Module): Trained model\n        test_loader (DataLoader): Test data loader\n        criterion (nn.Module): Loss function\n        device (torch.device): Device to run evaluation on\n        classes (list): List of class names\n        \n    Returns:\n        dict: Dictionary containing various performance metrics\n    \"\"\"\n    model.eval()\n    running_loss = 0.0\n    all_predictions = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for images, numerical_features, labels in test_loader:\n            images = images.to(device)\n            numerical_features = numerical_features.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images, numerical_features)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            \n            all_predictions.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    # Calculate metrics\n    accuracy = np.mean(np.array(all_predictions) == np.array(all_labels))\n    precision = precision_score(all_labels, all_predictions, average='weighted')\n    recall = recall_score(all_labels, all_predictions, average='weighted')\n    f1 = f1_score(all_labels, all_predictions, average='weighted')\n    conf_matrix = confusion_matrix(all_labels, all_predictions)\n    \n    # Calculate per-class metrics\n    per_class_precision = precision_score(all_labels, all_predictions, average=None)\n    per_class_recall = recall_score(all_labels, all_predictions, average=None)\n    per_class_f1 = f1_score(all_labels, all_predictions, average=None)\n    \n    metrics = {\n        'test_loss': running_loss / len(test_loader),\n        'accuracy': accuracy * 100,\n        'precision': precision * 100,\n        'recall': recall * 100,\n        'f1_score': f1 * 100,\n        'confusion_matrix': conf_matrix,\n        'per_class_metrics': {\n            'precision': dict(zip(classes, per_class_precision)),\n            'recall': dict(zip(classes, per_class_recall)),\n            'f1': dict(zip(classes, per_class_f1))\n        }\n    }\n    \n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T06:30:02.138755Z","iopub.execute_input":"2024-12-26T06:30:02.139082Z","iopub.status.idle":"2024-12-26T06:30:02.146512Z","shell.execute_reply.started":"2024-12-26T06:30:02.139056Z","shell.execute_reply":"2024-12-26T06:30:02.145462Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Function to plot the training and validation losess and accuracies cuvers during training","metadata":{}},{"cell_type":"code","source":"def plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies):\n    \"\"\"\n    Plot training and validation curves.\n    \n    Args:\n        train_losses (list): Training losses\n        val_losses (list): Validation losses\n        train_accuracies (list): Training accuracies\n        val_accuracies (list): Validation accuracies\n    \"\"\"\n    plt.figure(figsize=(12, 5))\n    \n    # Plot losses\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    # Plot accuracies\n    plt.subplot(1, 2, 2)\n    plt.plot(train_accuracies, label='Train Accuracy')\n    plt.plot(val_accuracies, label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T06:30:06.766999Z","iopub.execute_input":"2024-12-26T06:30:06.767292Z","iopub.status.idle":"2024-12-26T06:30:06.772526Z","shell.execute_reply.started":"2024-12-26T06:30:06.767272Z","shell.execute_reply":"2024-12-26T06:30:06.771713Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Confusion matrix","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(conf_matrix, classes, top_k=10):\n    class_totals = conf_matrix.sum(axis=1)\n    top_classes_idx = np.argsort(class_totals)[-top_k:]\n    \n    cm_subset = conf_matrix[top_classes_idx][:, top_classes_idx]\n    class_names_subset = [classes[i] for i in top_classes_idx]\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm_subset, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_names_subset,\n                yticklabels=class_names_subset)\n    plt.title(f'Confusion Matrix (Top {top_k} Classes)')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.xticks(rotation=45)\n    plt.yticks(rotation=45)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T06:30:12.968928Z","iopub.execute_input":"2024-12-26T06:30:12.969237Z","iopub.status.idle":"2024-12-26T06:30:12.974506Z","shell.execute_reply.started":"2024-12-26T06:30:12.969216Z","shell.execute_reply":"2024-12-26T06:30:12.973580Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Grid searching most optimal hyperparameters using 2 epochs","metadata":{}},{"cell_type":"code","source":"# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n\ndef grid_search():\n    \"\"\"Main function to run grid search and training pipeline.\"\"\"\n    # Define hyperparameter grid\n    param_grid = {\n        'batch_size': [32, 64, 128],\n        'learning_rate': [0.01, 0.001],\n        'dropout_rate': [0.5, 0.7],\n        'weight_decay': [1e-5, 1e-7],\n        'optimizer_name': ['adam', 'sgd', 'rmsprop'],\n        'scheduler_patience': [5, 10]\n    }\n    \n    # Image transformations\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n    ])\n    \n    # Load and preprocess data\n    features_scaled, labels_encoded, classes = load_and_preprocess_data('/kaggle/working/train.csv', '/kaggle/working/images')\n    \n    # Split data into train, validation, and test sets\n    X_temp, X_test, y_temp, y_test = train_test_split(\n        features_scaled, labels_encoded,\n        test_size=0.2, random_state=42, stratify=labels_encoded\n    )\n    \n    X_train, X_val, y_train, y_val = train_test_split(\n        X_temp, y_temp,\n        test_size=0.2, random_state=42, stratify=y_temp\n    )\n    \n    # Create datasets\n    train_dataset = LeafDataset(X_train, '/kaggle/working/images', y_train, transform=transform)\n    val_dataset = LeafDataset(X_val, '/kaggle/working/images', y_val, transform=transform)\n    test_dataset = LeafDataset(X_test, '/kaggle/working/images', y_test, transform=transform)\n    \n    # Initialize device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Generate all combinations of hyperparameters\n    param_combinations = [dict(zip(param_grid.keys(), v)) \n                         for v in itertools.product(*param_grid.values())]\n    \n    # Store results\n    results = []\n    best_val_accuracy = 0\n    best_params = None\n    best_model_state = None\n    \n    # Grid search\n    for params in tqdm(param_combinations, desc=\"Grid Search Progress\"):\n        # Create dataloaders with current batch size\n        train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=params['batch_size'])\n        \n        # Initialize model\n        model = LeafCNN(\n            num_numerical_features=X_train.shape[1],\n            num_classes=len(classes),\n            dropout_rate=params['dropout_rate']\n        ).to(device)\n        \n        # Initialize optimizer\n        if params['optimizer_name'] == 'adam':\n            optimizer = optim.Adam(model.parameters(), \n                                 lr=params['learning_rate'], \n                                 weight_decay=params['weight_decay'])\n        elif params['optimizer_name'] == 'sgd':\n            optimizer = optim.SGD(model.parameters(), \n                                lr=params['learning_rate'], \n                                momentum=0.9, \n                                weight_decay=params['weight_decay'])\n        else:  # adamw\n            optimizer = optim.AdamW(model.parameters(), \n                                  lr=params['learning_rate'], \n                                  weight_decay=params['weight_decay'])\n        \n        # Initialize loss function and scheduler\n        criterion = nn.CrossEntropyLoss()\n        scheduler = ReduceLROnPlateau(optimizer, \n                                    mode='min', \n                                    factor=0.1, \n                                    patience=params['scheduler_patience'], \n                                    verbose=True)\n        \n        # Train model\n        train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n            model, train_loader, val_loader, criterion, optimizer, scheduler, \n            num_epochs=2, device=device\n        )\n        \n        # Get final validation accuracy\n        final_val_accuracy = val_accuracies[-1]\n        \n        # Store results\n        results.append({\n            'params': params,\n            'final_val_accuracy': final_val_accuracy,\n            'final_val_loss': val_losses[-1]\n        })\n        \n        # Update best model if necessary\n        if final_val_accuracy > best_val_accuracy:\n            best_val_accuracy = final_val_accuracy\n            best_params = params\n            best_model_state = model.state_dict()\n        \n        # Print current results\n        print(f\"\\nParameters: {params}\")\n        print(f\"Validation Accuracy: {final_val_accuracy:.2f}%\")\n        print(f\"Validation Loss: {val_losses[-1]:.4f}\")\n    \n    # Sort results by validation accuracy\n    results.sort(key=lambda x: x['final_val_accuracy'], reverse=True)\n    \n    # Print top 5 configurations\n    print(\"\\nTop 5 Configurations:\")\n    for i, result in enumerate(results[:5]):\n        print(f\"\\n{i+1}. Validation Accuracy: {result['final_val_accuracy']:.2f}%\")\n        print(f\"Parameters: {result['params']}\")\n    \n    # Load best model and evaluate on test set\n    best_model = LeafCNN(\n        num_numerical_features=X_train.shape[1],\n        num_classes=len(classes),\n        dropout_rate=best_params['dropout_rate']\n    ).to(device)\n    best_model.load_state_dict(best_model_state)\n    \n    test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'])\n    test_metrics = evaluate_model(best_model, test_loader, criterion, device, classes)\n    \n    # Print test metrics for best model\n    print(\"\\nBest Model Test Metrics:\")\n    print(f\"Loss: {test_metrics['test_loss']:.4f}\")\n    print(f\"Accuracy: {test_metrics['accuracy']:.2f}%\")\n    print(f\"Precision: {test_metrics['precision']:.2f}%\")\n    print(f\"Recall: {test_metrics['recall']:.2f}%\")\n    print(f\"F1 Score: {test_metrics['f1_score']:.2f}%\")\n    \n    # Plot confusion matrix\n    plot_confusion_matrix(test_metrics['confusion_matrix'], classes)\n    \n    # Save best model\n    torch.save({\n        'model_state_dict': best_model_state,\n        'best_params': best_params,\n        'classes': classes,\n        'test_metrics': test_metrics,\n        'grid_search_results': results\n    }, 'best_leaf_classifier_checkpoint.pth')\n\nif __name__ == '__main__':\n    grid_search()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-26T06:42:24.642382Z","iopub.execute_input":"2024-12-26T06:42:24.642751Z","iopub.status.idle":"2024-12-26T07:03:37.093070Z","shell.execute_reply.started":"2024-12-26T06:42:24.642711Z","shell.execute_reply":"2024-12-26T07:03:37.092197Z"},"_kg_hide-output":true,"jupyter":{"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def best_model():\n    \"\"\"Main function to run the training and evaluation pipeline.\"\"\"\n    # Hyperparameters\n    batch_size = 32\n    learning_rate = 0.01\n    num_epochs = 30\n    dropout_rate = 0.5\n    weight_decay = 1e-7\n    early_stopping_patience = 10  # Patience for early stopping\n\n    # Image transformations\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n    ])\n\n    # Load and preprocess data\n    features_scaled, labels_encoded, classes = load_and_preprocess_data('/kaggle/working/train.csv', '/kaggle/working/images')\n\n    # Split data into train, validation, and test sets\n    X_temp, X_test, y_temp, y_test = train_test_split(\n        features_scaled, labels_encoded,\n        test_size=0.2, random_state=42, stratify=labels_encoded\n    )\n\n    X_train, X_val, y_train, y_val = train_test_split(\n        X_temp, y_temp,\n        test_size=0.2, random_state=42, stratify=y_temp\n    )\n\n    # Create datasets and dataloaders\n    train_dataset = LeafDataset(X_train, '/kaggle/working/images', y_train, transform=transform)\n    val_dataset = LeafDataset(X_val, '/kaggle/working/images', y_val, transform=transform)\n    test_dataset = LeafDataset(X_test, '/kaggle/working/images', y_test, transform=transform)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n    # Initialize model and training components\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = LeafCNN(\n        num_numerical_features=X_train.shape[1],\n        num_classes=len(classes),\n        dropout_rate=dropout_rate\n    ).to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    # scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True) # Patience must be the same as early_stopping\n\n    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)\n    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)  # Patience must be the same as early_stopping\n\n\n    # Train model\n    train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n        model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, early_stopping_patience\n    )\n\n    # Plot training curves\n    plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies)\n\n    # Evaluate model on test set\n    test_metrics = evaluate_model(model, test_loader, criterion, device, classes)\n\n    # Print test metrics\n    print(\"\\nTest Set Metrics:\")\n    print(f\"Loss: {test_metrics['test_loss']:.4f}\")\n    print(f\"Accuracy: {test_metrics['accuracy']:.2f}%\")\n    print(f\"Precision: {test_metrics['precision']:.2f}%\")\n    print(f\"Recall: {test_metrics['recall']:.2f}%\")\n    print(f\"F1 Score: {test_metrics['f1_score']:.2f}%\")\n\n    # Plot confusion matrix\n    plot_confusion_matrix(test_metrics['confusion_matrix'], classes)\n\n    # Save model\n    torch.save({\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict(),\n        'classes': classes,\n        'test_metrics': test_metrics\n    }, 'best_model.pth')\n\n\nbest_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T08:05:07.204430Z","iopub.execute_input":"2024-12-26T08:05:07.204852Z","iopub.status.idle":"2024-12-26T08:07:15.644023Z","shell.execute_reply.started":"2024-12-26T08:05:07.204818Z","shell.execute_reply":"2024-12-26T08:07:15.643141Z"}},"outputs":[],"execution_count":null}]}